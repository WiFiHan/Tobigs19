{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week1_Library 과제"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Library 와 Framework 의 차이 간단하게 서술하시오. (100자 내외)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library란 컴퓨터 프로그램이 자주 사용하는 코드 및 함수의 집합으로, tensorflow나 numpy를 예로 들 수 있다. Framework란 컴퓨터 프로그램 개발에 사용되는 골격으로, Android나 Spring을 예로 들 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. 딥러닝과 머신러닝의 관계 및 특징, 차이 간단하게 서술하시오. (200자 내외)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝은 기계가 어떤 경험적 자료를 바탕으로 그것의 성능을 개선할 수 있는 일체의 프로그램 개발 방식을 의미한다. 딥러닝은 이러한 머신러닝 방식 중 하나로, 딥러닝 알고리즘은 기본적으로 선형변환(batch dim이 1일 경우 행렬곱)을 여러 계층 합성하는 방식으로 구성된다. 딥러닝 알고리즘의 성능은 미분을 통해 오차를 감소시키는 방향으로 선형변환 파라미터의 값을 점진적으로 변화시키는 방식으로 개선된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. 아래의 코드에 주석 달기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transfroms\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(45)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(45)\n",
    "print(device + \" is available\")\n",
    "\n",
    "\"\"\"\n",
    "신경망 개발에 필요한 파이토치 라이브러리를 import하였다.\n",
    "만약 CUDA 기반 GPU를 쓸 수 있다면 GPU를 사용하고, 그렇지 않으면 CPU를 사용한다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "\n",
    "\"\"\"\n",
    "학습에 필요한 각종 파라미터 중 User가 직접 정해줘야 하는 파라미터를\n",
    "위와 같이 설정하였다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor() \n",
    "    ])\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "MNIST 데이터셋을 다운받아\n",
    "훈련에 필요한 train set과 검증에 필요한 test set으로 나누었다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "examples = enumerate(train_set)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape\n",
    "\n",
    "\"\"\"\n",
    "위의 데이터셋을 각각 batch size 100으로 묶어\n",
    "한 번에 batch size만큼 load한다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvNet(nn.Module):\n",
    "  def __init__(self): \n",
    "        super(ConvNet, self).__init__() \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) \n",
    "        self.drop2D = nn.Dropout2d(p=0.25, inplace=False) \n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(320,100) \n",
    "        self.fc2 = nn.Linear(100,10) \n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "        x = F.relu(self.mp(self.conv1(x))) \n",
    "        x = F.relu(self.mp(self.conv2(x))) \n",
    "        x = self.drop2D(x) \n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "  \n",
    "\"\"\"\n",
    "CNN 기반 네트워크를 만들고, 각 층마다 호출될 Forward 함수를 설계했다.\n",
    "해당 네트워크는 Conv -> ReLU -> Conv -> ReLU -> Dropout -> MaxPooling -> Linear -> Linear -> Softmax \n",
    "의 결과를 다음 계층으로 전달한다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ConvNet().to(device) \n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\"\"\"\n",
    "위에서 만든 모델이 전파한 값에 대한 손실함수는 크로스엔트로피 함수로 설정하며,\n",
    "Optimizer는 가장 빈번히 쓰이는 Adam Optimizer이다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(epochs): \n",
    "    avg_cost = 0\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad() \n",
    "        hypothesis = model(data)\n",
    "        cost = criterion(hypothesis, target) \n",
    "        cost.backward()\n",
    "        optimizer.step() \n",
    "        avg_cost += cost / len(train_loader) \n",
    "    print('[Epoch: {:>4}]  cost = {:>.9}'.format(epoch + 1, avg_cost))\n",
    "\n",
    "\"\"\"\n",
    "5에포크동안\n",
    "Train 데이터와 정답값을 받아\n",
    "Model에 데이터를 넣어 Hypothesis와 Target 사이의 Loss를 계산한다.\n",
    "각 에포크동안 평균 Loss를 출력한다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "with torch.no_grad(): \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        out = model(data)\n",
    "        preds = torch.max(out.data, 1)[1] \n",
    "        total += len(target) \n",
    "        correct += (preds==target).sum().item() \n",
    "        \n",
    "    print('Test Accuracy: ', 100.*correct/total, '%')\n",
    "\n",
    "\"\"\"\n",
    "Test 데이터와 정답값을 바탕으로 검증한 뒤,\n",
    "평균정답률(Accuracy)를 산출한다.\n",
    "\"\"\"\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첫 정규세션 들으시느라 고생 많으셨습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e593ac106456af50ce7af38f9671c411b49d6cd90f9b885e167f0f594e09038c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
